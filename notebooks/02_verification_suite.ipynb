{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 2: Rigid Verification Suite\n",
                "\n",
                "## Checklist\n",
                "1. Embedding Model Consistency (384 dims, all-MiniLM-L6-v2)\n",
                "2. Chunking Quality Verification\n",
                "3. Embedding Integrity (No NaNs, correct shape)\n",
                "4. Vector Store Persistence\n",
                "5. Semantic Retrieval Sanity Tests (5 queries)\n",
                "6. Metadata Completeness\n",
                "7. Filtering Readiness\n",
                "8. Performance Reality Check"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import chromadb\n",
                "from sentence_transformers import SentenceTransformer\n",
                "import numpy as np\n",
                "import time\n",
                "import pandas as pd\n",
                "\n",
                "# Config\n",
                "VECTOR_STORE_DIR = '../vector_store'\n",
                "EMBEDDING_MODEL_NAME = 'all-MiniLM-L6-v2'\n",
                "EXPECTED_DIM = 384"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Embedding Model Consistency\n",
                "**Verify:** Embedding dimension = 384. Model = all-MiniLM-L6-v2."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Loading model: {EMBEDDING_MODEL_NAME}...\")\n",
                "model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
                "\n",
                "test_text = \"This is a test sentence for dimension check.\"\n",
                "embedding = model.encode(test_text)\n",
                "\n",
                "print(f\"Model Output Shape: {embedding.shape}\")\n",
                "if embedding.shape[0] == EXPECTED_DIM:\n",
                "    print(\"‚úÖ PASS: Embedding dimension is 384.\")\n",
                "else:\n",
                "    print(f\"‚ùå FAIL: Expected 384, got {embedding.shape[0]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2 & 6. Chunking Quality & Metadata Completeness\n",
                "**Verify:** Chunks are readable (size ~500), Metadata contains all fields."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "client = chromadb.PersistentClient(path=VECTOR_STORE_DIR)\n",
                "collection = client.get_collection(\"complaints_rag\")\n",
                "\n",
                "# Fetch a few random items\n",
                "results = collection.get(limit=5, include=['documents', 'metadatas'])\n",
                "\n",
                "required_metadata = ['complaint_id', 'product', 'issue', 'company', 'date_received', 'chunk_index', 'total_chunks']\n",
                "\n",
                "print(f\"INSPECTING {len(results['documents'])} CHUNKS:\\n\")\n",
                "\n",
                "for i, (doc, meta) in enumerate(zip(results['documents'], results['metadatas'])):\n",
                "    print(f\"[Chunk {i+1}]\")\n",
                "    print(f\"Length: {len(doc)} chars\")\n",
                "    print(f\"Text (First 100 chars): {doc[:100]}...\")\n",
                "    \n",
                "    # Check Metadata\n",
                "    missing = [key for key in required_metadata if key not in meta]\n",
                "    if not missing:\n",
                "        print(\"‚úÖ Metadata Complete\")\n",
                "    else:\n",
                "        print(f\"‚ùå Metadata Missing: {missing}\")\n",
                "    print(\"-\" * 50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Embedding Integrity\n",
                "**Verify:** No NaNs, correct count."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ChromaDB doesn't easily let us fetch ALL embeddings as numpy arrays efficiently for thousands without memory hit,\n",
                "# but we can fetch a batch to validate.\n",
                "vec_results = collection.get(limit=100, include=['embeddings'])\n",
                "embeddings_sample = np.array(vec_results['embeddings'])\n",
                "\n",
                "if np.isnan(embeddings_sample).any():\n",
                "    print(\"‚ùå FAIL: NaNs detected in embeddings.\")\n",
                "else:\n",
                "    print(\"‚úÖ PASS: No NaNs in sample batch.\")\n",
                "    \n",
                "if embeddings_sample.shape[1] == EXPECTED_DIM:\n",
                "    print(\"‚úÖ PASS: Stored embeddings have correct dimension (384).\")\n",
                "else:\n",
                "    print(f\"‚ùå FAIL: Stored dimension {embeddings_sample.shape[1]}.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Semantic Retrieval Sanity Tests (5 Queries)\n",
                "**Verify:** Relevance and intuition."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "queries = [\n",
                "    \"Credit card billing disputes\",\n",
                "    \"Unauthorized transactions\",\n",
                "    \"Delayed money transfers\",\n",
                "    \"High interest on personal loans\",\n",
                "    \"Account closure issues\"\n",
                "]\n",
                "\n",
                "for q in queries:\n",
                "    print(f\"\\nüîç Query: '{q}'\")\n",
                "    start_time = time.time()\n",
                "    q_vec = model.encode([q]).tolist()\n",
                "    results = collection.query(query_embeddings=q_vec, n_results=1)\n",
                "    latency = (time.time() - start_time) * 1000\n",
                "    \n",
                "    doc = results['documents'][0][0]\n",
                "    meta = results['metadatas'][0][0]\n",
                "    \n",
                "    print(f\"   ‚è±Ô∏è Latency: {latency:.2f} ms\")\n",
                "    print(f\"   Product: {meta.get('product')}\")\n",
                "    print(f\"   Issue: {meta.get('issue')}\")\n",
                "    print(f\"   Snippet: {doc[:150]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Filtering Readiness\n",
                "**Verify:** Filtering by product works."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Testing Filter: Product = 'Credit card'...\")\n",
                "filter_query = \"fees\"\n",
                "q_vec_f = model.encode([filter_query]).tolist()\n",
                "\n",
                "results_f = collection.query(\n",
                "    query_embeddings=q_vec_f,\n",
                "    n_results=5,\n",
                "    where={\"product\": \"Credit card\"}\n",
                ")\n",
                "\n",
                "all_credit_cards = all(meta['product'] == 'Credit card' for meta in results_f['metadatas'][0])\n",
                "if all_credit_cards:\n",
                "    print(\"‚úÖ PASS: All results match filter 'Credit card'.\")\n",
                "else:\n",
                "    print(\"‚ùå FAIL: Filter leaked other products.\")\n",
                "    \n",
                "print(\"Sample Products Returned:\", [m['product'] for m in results_f['metadatas'][0]])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}