{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Exploratory Data Analysis and Data Preprocessing\n",
    "\n",
    "## Objective\n",
    "Understand the structure, content, and quality of the complaint data and prepare it for the RAG pipeline.\n",
    "\n",
    "## Checklist\n",
    "1. Load Raw CFPB Dataset\n",
    "2. Initial Exploratory Data Analysis (EDA)\n",
    "3. Filter to Business Scope\n",
    "4. Text Cleaning & Normalization\n",
    "5. Save Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Environment Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Configuration\n",
    "RAW_DATA_PATH = '../data/raw/complaints.csv'\n",
    "PROCESSED_DATA_PATH = '../data/processed/filtered_complaints.csv'\n",
    "\n",
    "# Ensure directores exist\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "os.makedirs('eda_outputs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Raw CFPB Dataset\n",
    "Loading the dataset efficiently. Since the file is large, we will use chunking or load a sample first for EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample to inspect columns and types\n",
    "df_sample = pd.read_csv(RAW_DATA_PATH, nrows=5)\n",
    "print(\"Shape (Sample):\", df_sample.shape)\n",
    "print(\"Columns:\", df_sample.columns.tolist())\n",
    "print(\"\\nData Types:\")\n",
    "print(df_sample.dtypes)\n",
    "\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial Exploratory Data Analysis (EDA)\n",
    "We will iterate through the dataset to calculate aggregate statistics without loading it all into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_counts = {}\n",
    "narrative_counts = {'total': 0, 'with_narrative': 0, 'null_narrative': 0}\n",
    "narrative_lengths = []\n",
    "\n",
    "chunk_size = 100000\n",
    "\n",
    "print(\"Processing dataset for EDA...\")\n",
    "for chunk in pd.read_csv(RAW_DATA_PATH, chunksize=chunk_size, low_memory=False):\n",
    "    # Product Distribution\n",
    "    if 'Product' in chunk.columns:\n",
    "        counts = chunk['Product'].value_counts()\n",
    "        for prod, count in counts.items():\n",
    "            product_counts[prod] = product_counts.get(prod, 0) + count\n",
    "    \n",
    "    # Narrative Availability\n",
    "    if 'Consumer complaint narrative' in chunk.columns:\n",
    "        chunk_total = len(chunk)\n",
    "        narrative_counts['total'] += chunk_total\n",
    "        non_null = chunk['Consumer complaint narrative'].notnull().sum()\n",
    "        narrative_counts['with_narrative'] += non_null\n",
    "        narrative_counts['null_narrative'] += (chunk_total - non_null)\n",
    "        \n",
    "        # Length of non-null narratives\n",
    "        valid = chunk['Consumer complaint narrative'].dropna()\n",
    "        lengths = valid.astype(str).apply(lambda x: len(x.split())).tolist()\n",
    "        narrative_lengths.extend(lengths)\n",
    "        \n",
    "print(\"EDA Processing Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Product Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_df = pd.DataFrame(list(product_counts.items()), columns=['Product', 'Count']).sort_values('Count', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=prod_df.head(15), x='Count', y='Product')\n",
    "plt.title('Top 15 Products by Complaint Volume')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Narrative Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Narrative Counts:\", narrative_counts)\n",
    "missing_pct = (narrative_counts['null_narrative'] / narrative_counts['total']) * 100\n",
    "print(f\"Percentage of complaints without narrative: {missing_pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Narrative Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_series = pd.Series(narrative_lengths)\n",
    "print(lengths_series.describe())\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(narrative_lengths, bins=50, kde=True)\n",
    "plt.title('Distribution of Complaint Narrative Lengths (Word Count)')\n",
    "plt.xlabel('Word Count')\n",
    "plt.xlim(0, 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filter to Business Scope & 5. Text Cleaning\n",
    "Filtering for: Credit card, Personal loan, Savings account, Money transfers.\n",
    "Removing empty narratives.\n",
    "Cleaning text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = text.replace('xx/xx/xxxx', '')\n",
    "    text = text.replace('xxxx', '')\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "keywords = ['credit card', 'personal loan', 'savings', 'money transfer']\n",
    "\n",
    "processed_chunks = []\n",
    "\n",
    "print(\"Filtering and cleaning...\")\n",
    "for chunk in pd.read_csv(RAW_DATA_PATH, chunksize=chunk_size, low_memory=False):\n",
    "    if 'Product' not in chunk.columns or 'Consumer complaint narrative' not in chunk.columns:\n",
    "        continue\n",
    "        \n",
    "    chunk['Product_Normalized'] = chunk['Product'].astype(str).str.lower()\n",
    "    \n",
    "    mask_product = chunk['Product_Normalized'].apply(lambda x: any(k in x for k in keywords))\n",
    "    mask_narrative = chunk['Consumer complaint narrative'].notnull()\n",
    "    \n",
    "    filtered_chunk = chunk[mask_product & mask_narrative].copy()\n",
    "    \n",
    "    if len(filtered_chunk) > 0:\n",
    "        filtered_chunk['cleaned_narrative'] = filtered_chunk['Consumer complaint narrative'].apply(clean_text)\n",
    "        \n",
    "        rename_map = {\n",
    "            'Complaint ID': 'complaint_id',\n",
    "            'Product': 'product',\n",
    "            'Issue': 'issue',\n",
    "            'Sub-issue': 'sub_issue',\n",
    "            'Company': 'company',\n",
    "            'Date received': 'date_received'\n",
    "        }\n",
    "        \n",
    "        cols_to_keep = list(rename_map.keys()) + ['cleaned_narrative']\n",
    "        existing_cols = [c for c in cols_to_keep if c in filtered_chunk.columns]\n",
    "        \n",
    "        final_chunk = filtered_chunk[existing_cols].rename(columns=rename_map)\n",
    "        processed_chunks.append(final_chunk)\n",
    "\n",
    "final_df = pd.concat(processed_chunks, ignore_index=True)\n",
    "print(f\"Final Dataset Shape: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(PROCESSED_DATA_PATH, index=False)\n",
    "print(f\"Saved to {PROCESSED_DATA_PATH}\")\n",
    "\n",
    "# Verification\n",
    "print(final_df.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
